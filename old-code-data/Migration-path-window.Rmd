---
title: "Migration-path-window"
output: html_document
date: '2022-10-19'
---

At this stage, this file is **archived**. It represents previous coding attempts and the relevant parts have been translated over to the migration-paths.rmd file. 

This file uses GAMs to calculate the yearly migration paths for the 15 species of interest, as well as the start/end dates of those migrations for the 15 species of interest. calcuates using average of multiple parameter settings (k, g) 
 
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(mgcv)
library(features)
library(geosphere)
library(dplyr)
```

#Needs to be checked before running the codes. 
1. Before loading the data, make sure the users in the correct path. 
2. The current version (end of the fall semester 2022) only worked with the one migratory species, Bombycilla_cedrorum. 
3. Before starting with this migration path window, check if the two species that did not work in migration path rmd file. (The codes for the two species did not work). 
4. If being able to fix and add the two species from the migration path rmd file, make sure to update the "weighted_mean_locs" file and then read the file here. 
5. Make sure all of the packages and library are running. Sometimes packages and library causes issues with running code, then try "packages name::function name" which will let the code run. For example, dplyr::select. 
6. If the data frame is relevant, try to save it using "saveRDS(what you want to call the data frame, file = "the actual name of the data frame.RDS"). 
Calling the data can be done by "readRDS("name of the data frame.rds")
7. Try to work with a single species, multiple species, and then run the whole species
8. Might need the packages that was used in "migration-path" file. 
9. By the time for summer 2023, the 2022 data should be filled out. Therefore, weighted_mean_locs data frame needs to be updated. For this, check the google document file. 

```{r}
#Step 1:loading the original data (the data is from the migration-path rmd file)

#weighted_mean_locs is the centroid latitude and longitude of each migratory speices. 
weighted_mean_locs <- readRDS("data_2023/weighted_mean_locs_2024.rds")
weighted_mean_locs

#Step 2: taking single species,Bombycilla cedrorum and saving it as Bombycilla_centroids. (In the future no need to take out the species when running the whole migratory species)
  #need only species, year, day, longitude, and latitude
  #renaming the weighted_lat and weighted_long as centroid_longitude and centroid_latitude
Bombycilla_centroids <-weighted_mean_locs %>% 
  filter(species == "Bombycilla cedrorum") %>%
  dplyr::select(species, year, day, weighted_lon,weighted_lat) %>%
  rename(centroid_longitude = weighted_lon, centroid_latitude = weighted_lat)

#Step 3:checking if it is right data frame                                 
Bombycilla_centroids

#Step 4: sorting the years (will have year 2008 to 2022 with day 1 to 365 or 366)
years <- sort(unique(Bombycilla_centroids$year))
```

#Supplementray code on calculating daily basis 

#FIXME: Not sure why we need max and min latitude by each day? DELETE?
If so, can also delete the saved .rds file, as it isn't really needed or useful
```{r}
#calculating daily basis 
#calculating the maximum longitude and latitude for each year for Bombycilla_c
max_value_day<-Bombycilla_centroids %>%
  group_by(species, year,day) %>% #grouping by species, year, and day 
  filter(centroid_latitude == max(centroid_latitude, na.rm=TRUE)) %>% #finding the daily maximum latitude and naming it as centroid_latitude
  rename(
    max_lat = centroid_latitude,
    max_lon = centroid_longitude
    )
max_value_day 

#calculating the minimum longitude and latitude for each year for Bombycilla_c
min_value_day <- Bombycilla_centroids %>%
  group_by(species, year,day) %>%
  filter(centroid_latitude == min(centroid_latitude, na.rm=TRUE)) %>% #finding the daily minimum latitude and naming it as centroid_latitude
  rename(
    min_lat = centroid_latitude,
    min_lon = centroid_longitude
    )
min_value_day

#combining max and min value for Bombycilla_c in daily 
maxmin_val_day <- merge(max_value_day, min_value_day, by = c("species", "year")) #combining max_value_day and mim_value_day data frames by species and year columns
maxmin_val_day

#taking only max_lon and max_lat
max_day <- maxmin_val_day[,4:5]
#taking only min_lon and min_lat
min_day <- maxmin_val_day[,7:8]

#calculating the total distance for Bombycilla_cedrorum
maxmin_val_day$total_distance <- round(distVincentyEllipsoid(max_day, min_day)/1000) #using the distVincentlyellipsiod, calculating the total distance by taking the maximum and minim latidue day
maxmin_val_day

#dropping day.y and renaming day.x to day(only kepping the latitude day)
maxmin_val_day<-maxmin_val_day %>% 
  dplyr::select(-c(day.x)) %>%  #keeping the latitude dates
  rename(latitude_dates = day.y) #renmaing the day.y as latitude_dates

maxmin_val_day 

saveRDS(maxmin_val_day, file = "data_2023/maxmin_val_day_2023.RDS") 
```
#FIXME: Not sure why we need max and min latitude day by each year? DELETE?
If so, can also delete the saved .rds files, as they aren't really needed or useful
```{r}
#Step 5: calculating yearly
  #calculating the maximum longitude and latitude for each year for Bombycilla_c
max_value_year<-Bombycilla_centroids %>%
  group_by(species, year) %>%
  filter(centroid_latitude == max(centroid_latitude, na.rm=TRUE)) %>% #finding the daily maximum latitude and naming it as centroid_latitude
  rename(
    max_lat = centroid_latitude,
    max_lon = centroid_longitude
    )
max_value_year

#saveRDS(max_value_year, file = "data_2023/max_value_year_2023.RDS") 

#calculating the minimum longitude and latitude for each year for Bombycilla_c
min_value_year <- Bombycilla_centroids %>%
  group_by(species, year) %>%
  filter(centroid_latitude == min(centroid_latitude, na.rm=TRUE)) %>% #finding the daily minimum latitude and naming it as centroid_latitude
  rename(
    min_lat = centroid_latitude,
    min_lon = centroid_longitude
    )
min_value_year

#saveRDS(min_value_year, file = "data_2023/min_value_year_2023.RDS") 

#combining max and min value for Bombycilla_c in daily 
maxmin_val_year <- merge(max_value_year, min_value_year, by = c("species", "year"))
maxmin_val_year

#taking only max_lon and max_lat
max_year <- maxmin_val_year[,4:5]
#taking only min_lon and min_lat
min_year <- maxmin_val_year[,7:8]

#calculating the total distance for Bombycilla_cedrorum
maxmin_val_year$total_distance <- round(distVincentyEllipsoid(max_year, min_year)/1000) #using the distVincentlyellipsiod, calculating the total distance by taking the maximum and minimum latitude 
maxmin_val_year

#dropping day.y and renaming day.x to day(only keeping the latitude day)
maxmin_val_year<-maxmin_val_year %>% 
  dplyr::select(-c(day.x)) %>% 
  rename(latitude_dates = day.y)

maxmin_val_year 

#reordering the columns
colnames(maxmin_val_year)
maxmin_val_year <- maxmin_val_year[, c(1,2,5,3,4,6,7,8)]
maxmin_val_year

saveRDS(maxmin_val_year, file = "data_2023/maxmin_val_year_2023.RDS")
```



```{r}
# STILL NEED TO ADD K AND G VALS TO DATARESULT AND FIGURE OUT WHY SOME MISSING VALS

#Step 6: calculating the windows 
#No needs of tbl and tbl2 from Frank`s code 

#TODO: Figure out how to run the for loop. (try to make an empty dataframe that goes inside the for(jjj in _____) and try to run it.)
#    : All the dataframes at the ends are not correct. Season dataframe is giving out the year of 2009 with multiple same values, latitude is NULL. Merging dataframe looks correct but needs to be double check

# The output should look contains the columns of year, 1st derivative of spring begin, 2nd derivative of spring end, 2nd derivative fall begin, ad 1st derivative of fall end from year 2008 to 2021. 


#years <- sort(unique(Bombycilla_centroids$year)) #sorting the year <- IS THIS LINE NEEDED?
species <- unique(weighted_mean_locs$species)

dataresult<- NULL #creating an empty data set
latitude <- NULL #empty latitude


for(s in species){
  #filtering weighted_mean_locs to be just the species we want for this iteration of the loop
  centroids <-weighted_mean_locs %>% 
    filter(species == s) %>%
    dplyr::select(species, year, day, weighted_lon,weighted_lat) %>%
    rename(centroid_longitude = weighted_lon, centroid_latitude = weighted_lat)
  
  years <- 2009:2022 #need to take year from 2009 to 2021 so that it will include 2008 and 2022 as calculating the buffer year
  season <- NULL #empty season
  #latitude <- NULL #empty latitude
  for(jjj in 1:length(years)) {
    bufferyear <- c(years[jjj]-1, years[jjj], years[jjj]+1) #going to give three years(e.g. 2008, 2009, 2010 and then 2011, 2012, 2013, etc.)
    
    filterdowntothreeyrs <- centroids[centroids$year %in% bufferyear,] #saving the buffer years
    if(nrow(filterdowntothreeyrs)==0) next #checking
  
    filterdowntothreeyrs <- filterdowntothreeyrs[filterdowntothreeyrs$day != 366,] #taking out an extra day 366, so that each year has 365 days 
    endofyear1winter <- filterdowntothreeyrs[filterdowntothreeyrs$year == bufferyear[1] & filterdowntothreeyrs$day>319,] # taking a first year and day above 319 
    endofyear1winter$day2 <- endofyear1winter$day - 365 # subtracting 365 so that the day will begin from negative value to positive value 
  
    focalyear <- filterdowntothreeyrs[filterdowntothreeyrs$year == bufferyear[2],] #this is the focal year (second year)
    focalyear$day2 <- focalyear$day
  
    beginningofyear3winter <- filterdowntothreeyrs[filterdowntothreeyrs$year==bufferyear[3] & filterdowntothreeyrs$day<74,] ## taking a third year and day above 74 
    beginningofyear3winter$day2 <- beginningofyear3winter$day + 365 # adding 365 so that the day will begin from positive value that is above 365
    
    # we want to see that days staring from negative values to positive values(e.g. -50~4xx). This allows us to calculate the window of migration 
    merging <- rbind(endofyear1winter, focalyear, beginningofyear3winter) #merging all 
    merging <- merging[order(merging$day2),] #reordering the days
    
    if(nrow(merging)<300) next #checking

    gv <- seq(0,8,1) #test a range of different parameters to try to get the best gam
    kv <- seq(8,20,1) #test a range of parameters
    spring_max <- NULL
    autumn_min <- NULL
    prediction_out<- NULL
    dates <- NULL
    for(kkk in 1:length(kv)){
      for(ggg in 1:length(gv)){
        mdl <- gam(centroid_latitude ~ s(day2,k=kv[kkk]), 
                   data=merging, 
                   gamma=gv[ggg])
        x.data <- data.frame(day2=1:365)
        prediction_lat <- predict(mdl, newdata=x.data, type="response")           
        prediction_out <- cbind(prediction_out, prediction_lat) #predicted lats from gam fit
        
    ## derivatives
    ### features package extracts the 1st and 2nd derivatives
        feature <- features(x.data$day2, prediction_lat, smoother="glkerns",
                        control = list(npts=365))
        names(feature)
        first_derivative <- attributes(feature)$fits$d1
        spring_max <- c(spring_max, which.max(first_derivative[20:140])+19) #spring max date (day of year)
        autumn_min <- c(autumn_min, which.min(first_derivative[220:320])+219) #autumn min date (day of year)
        
        second_derivative <- attributes(feature)$fits$d2
        
    ## for all the dates within -- seek expert opinion and check that windows contain those dates, treat them as a buffer for a sensible set up to the analysis.
    ## spring (get three dates)
       spring_middle <- which.max(first_derivative[10:140]) + 9 #middle
       spring_beginning <- try(which.max(second_derivative[(spring_middle-40):spring_middle]) + (spring_middle-41), silent=TRUE) #beginning
       spring_end <- try(which.min(second_derivative[spring_middle:(spring_middle+40)]) + (spring_middle-1), silent=TRUE) #end
    ## autumn
       autumn_middle <- which.min(first_derivative[220:355]) + 219 #middle
       autumn_beginning <- try(which.min(second_derivative[(autumn_middle-40):autumn_middle]) + (autumn_middle-41), silent=TRUE) #beginning
       autumn_end <- try(which.max(second_derivative[autumn_middle:(autumn_middle+40)]) + (autumn_middle-1), silent=TRUE) #end
        
        ##
       if(class(spring_beginning)=="try-error") spring_beginning <- NA #checking 
       if(class(spring_end)=="try-error") spring_end <- NA #checking
       if(class(autumn_beginning)=="try-error") autumn_beginning <- NA #checking
       if(class(autumn_end)=="try-error") autumn_end <- NA #checking
        
        ##
        dates <- rbind(dates, data.frame(spring_beginning=spring_beginning, spring_middle=spring_middle, spring_end=spring_end, #combining all of the rows  
                                     autumn_beginning=autumn_beginning, autumn_middle=autumn_middle, autumn_end=autumn_end, k = kv[kkk], g = gv[ggg]))
      }
    }
  prediction_lat <- data.frame(rowMeans(prediction_out)) #average prediction

## mean first derivative
  spring_max <- mean(spring_max)
  autumn_min <- mean(autumn_min)
   
## quantile second derivative 
#### (method is to look across all the results to find the best line that would match what you'd expect to see)
#### recommend using 0.1 and 0.9, could be adjusted but found to work well on lots of species
#### removes some of the extreme outliers
  dates <- data.frame(species= s, #Bombycilla_centroids[,c("species")],
                  year=years[jjj],
                  spring_beginning=quantile(dates[is.finite(dates$spring_beginning),"spring_beginning"], 0.1, na.rm=TRUE), 
                  spring_middle=spring_max,
                  spring_end=quantile(dates[is.finite(dates$spring_end),"spring_end"], 0.9, na.rm=TRUE),
                  autumn_beginning=quantile(dates[is.finite(dates$autumn_beginning),"autumn_beginning"], 0.1, na.rm=TRUE), 
                  autumn_middle=autumn_min,
                  autumn_end=quantile(dates[is.finite(dates$autumn_end),"autumn_end"], 0.9, na.rm=TRUE))
    
    ##
  #season <- rbind(season, dates) #season out, stacks everything together into one datatable, results from dates quantile
  
  dataresult <- rbind(dataresult, dates) #season out, stacks everything together into one datatable, results from dates quantile

  latitude <- rbind(latitude, data.frame(species= rep(s, 365),
                                     year=rep(years[jjj], 365),
                                     day=1:365,
                                     lat=prediction_lat))
  }
  #if(is.null(season)) next
}
#dataresult
#latitude
#merging

```


```{r}
colnames(latitude)[4] <- "lat"
```


```{r}
#saveRDS(dataresult, file = "data_2023/migration_timing_2023.RDS") 
#saveRDS(latitude, file = "data_2023/daily_mean_lats_2023.RDS") 

dataresult <- readRDS("data_2023/migration_timing_2023.RDS")
latitude <- readRDS("data_2023/daily_mean_lats_2023.RDS")
```



##OLD CODE: Pasted over from the migration-paths.Rmd file on 3/3/25


# OLD GAM method and plots with varying k and g values
###FIXME: decide whether to keep or delete.
Moving here to the end of the file for now, until the rest of the code is vetted and results updated.


#FIXME: probably can't use this method for this subset of species; don't have strong enough N-S migration
### Trying the gam in a way that allows us to vary k and g, and record the results. 
#FIXME: Edit method for calculating dates
If this works, may choose to delete the above function and to delete the Estimate migration dates function, as it could be a better method, that calculates both at the same time.
```{r}
#FIXME: Double check results versus the original version of this code
#   conduct sanity checks, and walk through code and results with collabs to check method.

# The output should contain the columns of year, 1st derivative of spring begin, 2nd derivative of spring end, 2nd derivative fall begin, ad 1st derivative of fall end from year 2008 to 2021. 

Sys.time()
# create values for unique years and species names
# Only incldue the migratory species 
species <- c("Bombycilla_cedrorum", "Haemorhous_purpureus", 
          "Hylocichla_mustelina", "Junco_hyemalis", 
          "Setophaga_coronata", "Turdus_migratorius", 
          "Sialia_sialis", "Sturnella_magna", 
          "Sturnus_vulgaris")
#need to take year from 2009 to 2021 so that it will include 2008 and 2022 as calculating the buffer year
years <- 2009:2023 

# initialize empty lists to store results
dataresult <- NULL 
lat_lon <- NULL 


for(s in species){
  #filtering dataset to species, remove day 366 so all years have 365 days (lose one day from leap years)
  dat <-weighted_mean_locs %>%
    filter(species == s, day != 366) 
  
  for (y in years) {
    #subset dataset to 3-year period
    buffer_years <- c(y-1, y, y+1)
    filter_yr <- dat %>% filter(year %in% buffer_years) 
    
    # Skip if buffer_years is empty or if there are fewer than 300 rows
    if (nrow(filter_yr) < 300) next

    # separate winter start and end from focal year
    # the day2 mutations create a sequence of values ranging -45 to 438 to keep the days in order  
    winter_start <- filter_yr %>% filter(year == buffer_years[1] & day > 319) %>% mutate(day2 = day - 365)
    focal_year <- filter_yr %>% filter(year == buffer_years[2]) %>% mutate(day2 = day)
    winter_end <- filter_yr %>% filter(year == buffer_years[3] & day < 74) %>% mutate(day2 = day + 365)
    
    # merge back together, sorted by day2 to retain the correct sequence to estimating migration
    merged_dat <- bind_rows(winter_start, focal_year, winter_end) %>% arrange(day2)

    # Define ranges to test a range of parameters for k and gamma
    k_vals <- seq(8, 20, 1)
    gamma_vals <- seq(0, 8, 1)
    
    # initialize empty lists to store results in
    dates <- vector("list", length(gamma_vals) * length(k_vals))
    predictions_lon <- vector("list", length(gamma_vals) * length(k_vals))
    predictions_lat <- vector("list", length(gamma_vals) * length(k_vals))
    index <- 1
    
    for (k in k_vals){
      for (g in gamma_vals){
        
         # LONGITUDE MODEL
         mdl_lon <- gam(weighted_lon ~ s(day2, k = k), data = merged_dat, gamma = g)
         x_data_lon <- data.frame(day2 = 1:365)
         prediction_lon <- predict(mdl_lon, newdata = x_data_lon, type = "response")
         predictions_lon[[index]] <- prediction_lon
        
         # LATITUDE MODEL
         mdl_lat <- gam(weighted_lat ~ s(day2, k = k), data = merged_dat, gamma = g)
         x_data_lat <- data.frame(day2 = 1:365)
         prediction_lat <- predict(mdl_lat, newdata = x_data_lat, type = "response")
         predictions_lat[[index]] <- prediction_lat
          
         # features package extracts the 1st and 2nd derivatives
         feature <- features(x_data_lat$day2, prediction_lat, 
                             smoother = "glkerns", control = list(npts = 365))
         first_derivative <- attributes(feature)$fits$d1
         second_derivative <- attributes(feature)$fits$d2
         
         # Compute dates for spring and autumn from the derivatives
         # FIXME: Double check with FAL; changed a bit from previous code, tested for the same values
         #    Are the min and max methods in the right place? Are the bracketed values OK? 
         #    Are the quantiles set appropriately?
         # numeric values in brackets chosen to contain the expected migration windows for the species
          spring_begin <- which.min(second_derivative[10:140]) + 9
          spring_middle = which.max(first_derivative[10:140]) + 9
          spring_end <- which.max(second_derivative[10:140]) + 9
          
          autumn_begin <- which.max(second_derivative[220:355]) + 219
          autumn_middle = which.min(first_derivative[220:355]) + 219
          autumn_end <- which.min(second_derivative[220:355]) + 219
          
          dates[[index]] <- data.frame(
            species = s,
            year = y,
            k = k,
            g = g,
            spring_begin = spring_begin,
            spring_middle = spring_middle,
            spring_end = spring_end,
            autumn_begin = autumn_begin,
            autumn_middle = autumn_middle,
            autumn_end = autumn_end
          )
          index <- index + 1
        
      }
    }
    # Combine and summarize results
    dates_df <- do.call(rbind, dates)
    avg_dates <- dates_df %>%
     summarise(
      ## quantile second derivative 
      ### method looks across all results to find the best line to match what you'd expect to see
      ### recommend using 0.1 and 0.9, found to work well on lots of species
      ### removes some of the extreme outliers
      spring_beginning = quantile(spring_begin, 0.1, na.rm = TRUE),
      spring_middle = mean(spring_middle, na.rm = TRUE),
      spring_end = quantile(spring_end, 0.9, na.rm = TRUE),
      autumn_beginning = quantile(autumn_begin, 0.1, na.rm = TRUE),
      autumn_middle = mean(autumn_middle, na.rm = TRUE),
      autumn_end = quantile(autumn_end, 0.9, na.rm = TRUE)
      ) %>%
      mutate(species = s, year = y)
    
    # collects the average dates into new dataframe  
    # collects results averaged across the different k and g parameter setting for lon and lat
    dataresult[[length(dataresult) + 1]] <- avg_dates
    avg_pred_lon <- rowMeans(do.call(cbind, predictions_lon), na.rm = TRUE)
    avg_pred_lat <- rowMeans(do.call(cbind, predictions_lat), na.rm = TRUE)
    lat_lon[[length(lat_lon) + 1]] <- data.frame(species = rep(s, 365), year = rep(y, 365), 
                                                   day = 1:365, lat = avg_pred_lat, lon = avg_pred_lon)
  }
}  

# Bind results into final data frames
final_mig_dates <- bind_rows(dataresult)
final_gam <- bind_rows(lat_lon)
  
list(dataresult = final_mig_dates, lat_lon = final_gam)
Sys.time()
```

Plot the results of the averaged daily locations (centroids) for the migratory species by day of year
#FIXME: these results indicate something weird going on with the date estimation from the varying k and g code above.
```{r}
ggplot(final_gam, aes(day, lat, group=year)) + 
  geom_line(linewidth=0.1) +
  #scale_colour_manual(values = c("grey50", "blue")) +
  # Day 91 = April 1; Day 273 = Sep 30
  geom_vline(xintercept=c(91, 273), col="gray30") +
  geom_vline(data=final_mig_dates, aes(xintercept=spring_beginning, group=year), col="blue", linewidth=0.5) +
  geom_vline(data=final_mig_dates, aes(xintercept=spring_end, group=year), col="blue", linewidth=0.5) +
  geom_vline(data=final_mig_dates, aes(xintercept=autumn_end, group=year), col="orange", linewidth=0.5) +
  geom_vline(data=final_mig_dates, aes(xintercept=autumn_beginning, group=year), col="orange", linewidth=0.5) +
  xlab("Day of Year") + ylab("centroid latitude") +
  facet_wrap(~species, scales = "free_y", ncol=3) + 
  theme_bw()
```

#FIXME: Just showing for one species for now.
Plot the results showing the lat-lon path by year
```{r}
ggplot() + 
  geom_polygon(data=north_america, aes(x=long, y=lat, group=group), fill=NA, color="black")   +
  coord_sf(xlim = c(-103, -60), ylim = c(25, 55)) + #set limits without distorting boundaries
  geom_point(data=final_gam, aes(lon, lat), size=0.1, col="indianred", alpha=0.1) +
  labs(title = "Bombycilla cedrorum, migration pathway 2008-2023") +
  theme_minimal() + 
  theme(axis.line=element_blank(),axis.text.x=element_blank(),
          axis.text.y=element_blank(),axis.ticks=element_blank(),
          axis.title.x=element_blank(),
          axis.title.y=element_blank()) +
  facet_wrap(~year, ncol=4)
```


#FIXME: Delete after confirming we don't need. 
I made this version in an attempt to optimize the function, but it's not getting the same/accurate results, and it fails if a day is missing or is NA
FIXME: SOMETHING IS WEIRD WITH THE FUNCTION BELOW. DELETE AND REMOVE? IT IS FASTER, BUT DOESN'T WORK ACCURATELY, GETS DIFFERENT DPRED AND ESTIMATED DATES RESULTS FROM ABOVE (WHICH I HAVE VETTED BEFORE)
FIXME: Some dates are missing. We filled these back in during the missdates function, but then they were removed again after the distance calculation. Perhaps doing these at the same time or in a different order can reduce the problem. And what to do if the while date is NA? As long as there is a row, then if the latitude is NA it won't matter, right? Move this function way up in the code, and then check that it works OK?
```{r}
# Optimized function to estimate migration dates
Est3MigrationDates_test <- function(dat) {
  # Remove entries for day 1 to clean data at the start
  dat <- dat %>% filter(day != 1)
  years <- 2008:2024
  species_list <- unique(dat$species)
  
  # Initialize an empty dataframe
  df_dates <- data.frame(species = character(), year = integer(), spring = numeric(), maxlat = numeric(), fall = numeric())
  
  for (s in species_list) {
    for (y in years) {
      # Filter data for the current species and year
      dat_subset2 <- dat %>% filter(year == y, species == s, !is.na(lon)) #FIXME: removing rows causes a problem.
      
      # Skip if there's no data for the species and year
      if (nrow(dat_subset2) == 0) next

      print(paste0("species: ", s, "; year: ", y))
      
      # GAM model on latitude by julian date
      gam_model2 <- gam(lat ~ s(day, k = 40), data = dat_subset2, gamma = 1.5)
      xpred2 <- data.frame(day = 1:max(dat_subset2$day))
      dpred2 <- predict(gam_model2, newdata = xpred2, type = "response", se.fit = TRUE)
      
      # Define thresholds for spring and fall migrations
      spring_threshold2 <- min(dpred2$fit[2:120] + 2.56 * dpred2$se.fit[2:120], na.rm = TRUE)
      fall_threshold2 <- min(dpred2$fit[244:364] + 2.56 * dpred2$se.fit[244:364], na.rm = TRUE)
      
      # Calculate indices for spring and fall ranges
      spring_index <- intersect(11:190, dat_subset$day)
      fall_index <- intersect(220:355, dat_subset$day)
      
      # Maximum latitude days within spring and fall indices
      spring_max <- dat_subset %>% filter(day %in% spring_index) %>% slice_max(lat) %>% pull(day)
      fall_max <- dat_subset %>% filter(day %in% fall_index) %>% slice_max(lat) %>% pull(day)
      
      # Determine the start of spring migration
      spring_begin <- spring_max
      #FIXME: What to do when this particular day's latitude is NA?
      while (spring_begin > 1 && dat_subset$lat[dat_subset$day == spring_begin] > spring_threshold) {
        spring_begin <- spring_begin - 1
      }
      spring_begin <- spring_begin + 1
      
      # Determine the end of fall migration
      fall_end <- fall_max
      while (fall_end < max(dat_subset$day) && dat_subset$lat[dat_subset$day == fall_end] > fall_threshold) {
        fall_end <- fall_end + 1
      }
      fall_end <- fall_end - 1
      
      # Maximum latitude day for the center of the season
      max_lat <- dat_subset %>% slice_max(lat) %>% pull(day)
      
      # Append calculated dates to df_dates
      df_dates <- bind_rows(df_dates, data.frame(species = s, year = y, spring = spring_begin, 
                                                 maxlat = max_lat, fall = fall_end))
    }
  }
  return(df_dates)
}

Sys.time()
MigrationDates_test <- Est3MigrationDates_test(mig_spp_dailylocs)
Sys.time()
```