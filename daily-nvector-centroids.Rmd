---
title: "daily-nvector-centroids"
author: "Sarah Supp"
date: "2024-11-11"
output: html_document
---
##Code for cedar waxwing project, modified from eBird migration project (Supp et al. 2015)
(c) 2020-2024, Wisnefski, and Supp (PI)
based on code shared from La Sorte previous eBird project
supps@denison.edu
Denison University
Code is under development, part of NSF Multi-Institution Collaborative Award (2019-2025)

Birds evaluated include: 
* Cedar Waxwing (CEWA) _Bombycilla cedrorum_
* Robin (ROBI) _Turdus migratorius_
* Wood Thrush (WOTH) _Hylocichla mustelina_
* Yellow-rumped Warbler (YEWA) _setophaga coronata_
* Blue Jay (BLJA) _Cyanocitta cristata_
* European Starling (EUST) _Sturnus vulgaris_
* Eastern Bluebird (EABL) _Sialia sialis_
* Northern Mockingbird (NOMO) _Mimus polyglottos_
* Downy Woodpecker (DOWO) _Dryobates pubescens_
* Eastern Meadowlark (EAME) _Sturnella magna_
* White-breasted Nuthatch (WHNU) _Sitta carolinensis_
* Purple Finch (PUFI) _Haemorhous purpureus_
* Northern Cardinal (NOCA) _Cardinalis cardinalis_
* Dark-eyed Junco (DAJU) _Junco hyemalis_
* American Crow (AMCR) _Corvus brachyrhynchos_

**Disclaimer**: The nvector method used in this code file takes a long time to run (>15 hours on a desktop computer). Proceed accordingly.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(here)
library(tidyverse)
library(nvctr)
#library(geosphere) #FIXME: Check if needed, or loaded in the background with nvctr

```

If starting from scratch, input the three raw data files and merge together.
You need to bring in: 
1. a file with the bird observations (ebrd2.c)
2. a file with the total eBirder "effort" (eft.c)
3. a file with all the center locations for the POLYFID grid cells (locs)

*Please go to the file* called "process-raw-eBird-data.Rmd" to do this, if you don't already have the files named with the pattern dat_effort_****.RData".

**If you have already completed the initial steps** and have saved out the effort file, start here instead, with loading it.
Each species has it's own merged data file, and will be brought into one species data (spdata) file to work through the results.

```{r}
# list prepared .rds files for each of the species
files = list.files(path=here("data_2023/effort-merged_data_2023/"), pattern=glob2rx("dat_effort*.rds"))

# initialize empty dataframe
spdata <- data.frame(POLYFID=integer(), year=integer(), day=integer(),
                     count=integer(), x=numeric(), y=numeric(),
                     effort=numeric(), species=character())

# loop through each file to create one merged dataframe with all species
for (i in files) {
  dat <- readRDS(paste0(here("data_2023/effort-merged_data_2023/"),(i)))
  spdata <- bind_rows(spdata, dat)
}
```

[La Sorte et al. 2014](https://onlinelibrary.wiley.com/doi/full/10.1111/jbi.12328) defined western, central, and eastern flyways for migrating songbirds. These are general, but since our species include populations across the continent, and we are focused on eastern and midwestern populations of eastern redcedar, we should exclude western occurrences (<-103 longitude).

# FIXME: After checking the process-raw-eBird-data.Rmd file, can probably delete this note. 
Note: After running "process-raw-eBird-data" and re-run the *spdata*, the names of the variables (columns names) are changed. For example, in num_spobs function, count.x is not found in dat_effort. YEAR and DAYS have to be change into lower case letter. 

```{r}
# x = longitude 
dat_effort <- spdata %>%
  dplyr::filter(x >= -103) #set filter to only include occurrences within eastern and central flyway (-103 Longitude)

num_obs <- nrow(dat_effort)
paste0("The total number of observations for all species is ", num_obs, ".")

#print total number of observations (rows) and checklists by species
num_spobs <- dat_effort %>%
  #filter(year!=2023) %>%
  group_by(species) %>%
  summarise(nrow=n(),
            total_checklists=sum(count))
num_spobs

dat_effort %>%
  group_by(species, year) %>%
  summarise(nrow=n(),
            total=sum(count)) %>%
  ggplot(aes(as.numeric(year), total, group=species)) + 
  geom_point() + 
  geom_line() + 
  scale_y_log10() + 
  scale_x_continuous(breaks=seq(2008, 2024, 3)) +
  xlab("Year") +
  ylab("checklist count") +
  theme(legend.position=("none")) +
  facet_wrap(~species, ncol=3) + 
  theme_bw()
    # # set transparency
    # theme(
    #     panel.grid.major = element_blank(), 
    #     panel.grid.minor = element_blank(),
    #     #panel.background = element_rect(fill = "transparent",colour = NA),
    #     #plot.background = element_rect(fill = "transparent",colour = NA)
    #     ) 

# Figure for ESA 2021 poster was saved with transparency
# Figure for manuscript was made with white background
ggsave("figs/checklist_counts.png", height=10, width=8) #if want the background to be transparent, use: bg="transparent"

#saving copy of data before doing nvector stuff
saveRDS(dat_effort, "data_2023/dat_effort_2023.rds")
```


# Weight mean locations 
Weight species counts by eBirder effort counts for each cell

## Use the nvector method to convert the latitude and longitude values to 3 vectors 
These vectors represent longitude (x), latitude (y), and radius from the center of ellipsoidal earth (z) 

## WARNING: the function lat_lon2n_E takes a long time to run if you repeat on all rows. Only calculate once per unique value.
Code has been vectorized and optimized to resolve this challenge.


```{r}
#sorting dat_effort by year and day, adding column for frequency (count_checklists/total_effort)
dat_effort <- dat_effort %>%
  arrange(year, day) %>%
  mutate(freq = count / effort)

# make a new dataframe containing only the unique x and y values
# this will reduce redundant and lengthy calculations, saving computing time 
# x and y represents the center coordinates of the icosahedron cells, so there are many repeated combinations
unique_cell_coords <- dat_effort %>%
  distinct(x, y)

# Convert x and y coordinates into x, y, and z vectors: Nvector method
unique_cell_coords <- unique_cell_coords %>%
  mutate(
    rad_y = rad(y),
    rad_x = rad(x),
    new_vals = pmap(list(rad_y, rad_x), lat_lon2n_E),
    newx = map_dbl(new_vals, 1),
    newy = map_dbl(new_vals, 2),
    newz = map_dbl(new_vals, 3)
  ) %>%
  dplyr::select(-new_vals, -rad_y, -rad_x)  # Clean up temporary columns

# Join the new coordinates to the dat_effort dataframe, based on the x and y values
df <- dat_effort %>%
  left_join(unique_cell_coords, by = c("x", "y"))

# #Save to RDS file
saveRDS(df, "df_nvector_2024.rds") 
```


Using the nvector dataset, estimate the location centroid for each species on a given day (as a weighted mean)
*as a note, this code chunk also takes several minutes to run.
```{r}
#Putting species, year, and days into list in order
species_list <- unique(df$species)
year_list <- unique(df$year)
day_list <- unique(df$day)

#For each species of a given year and day, converting newx, newy, newz back into decimal meanx and meany
weighted_mean_locs <- NULL
for (i in 1:length(species_list)){
  species_df <- df[df$species==species_list[i],]
  
  for (j in 1:length(year_list)){
    year_df <- species_df[species_df$year==year_list[j],]
  
    for(k in 1:length(unique(year_df$day))){
        day_list <- sort(unique(year_df$day))
        day_df <- year_df[year_df$day==day_list[k],]
        mean_cal <- c(weighted.mean(day_df$newx, day_df$freq),
                      weighted.mean(day_df$newy, day_df$freq),
                      weighted.mean(day_df$newz, day_df$freq))
        mean_cal <- deg(n_E2lat_lon(mean_cal)) #degree func
        weighted_mean_locs <- rbind(weighted_mean_locs, data.frame(day=day_list[k], 
                                     weighted_lon=mean_cal[2], 
                                     weighted_lat=mean_cal[1],
                                     year=year_list[j],
                                     species=species_list[i]))
    }
  }
}  


sample <- df %>% group_by(species, year, day) %>% summarise(numcells = n(), numobs = sum(count))

weighted_mean_locs <- cbind(weighted_mean_locs, sample[c("numcells", "numobs")])

#Reordering the columns
weighted_mean_locs <- weighted_mean_locs[,c(5,4,1,2,3,6,7)]
```


## Add more detail to dates in the weighted mean location dataframe
A DATE and MONTH formatted column to mean_daily_locs dataframe.
An ID column is also added, which is an integer of each of the dates in order, 1-4383.
**It is important to note when converting to Dates that for this data type only (why!?!) R uses a 0 based index. This means Day 1 is 0. So to convert our "day of year" integers to a Year-Month-Day format, we need to use DAY-1 and YEAR.**

Note that this code defines the "winter" season as October-March. This is to label the time of year important for eastern redcedar cone production.
```{r}
weighted_mean_locs <- weighted_mean_locs %>%
  mutate(DAYm1 = day-1,
         origin = paste0(year, "-01-01"),
         date = as.Date(DAYm1, origin=origin), 
         month = month(date)) %>%
  mutate(winter = ifelse(month %in% c(10, 11, 12, 1, 2, 3), "winter", "non-winter")) %>%
  arrange(species,date) %>%
  ungroup() %>%
  mutate(ID = row_number()) %>%
  dplyr::select(-DAYm1, -origin)

saveRDS(weighted_mean_locs, "weighted_mean_locs_2023.rds")
```


Plot the new weights to visualize them
```{r}
#plot the weighted lons and lats by species, just to check
ggplot(weighted_mean_locs, aes(weighted_lon)) + 
  geom_histogram() + 
  facet_wrap(~species) + 
  theme_bw()

ggplot(weighted_mean_locs, aes(weighted_lat)) + 
  geom_histogram() + 
  facet_wrap(~species) + 
  theme_bw()

#check if weighted sd differs by time of the year (expect to be higher during migration, lower during breeding)
# LONGITUDE
ggplot(weighted_mean_locs, aes(day, weighted_lon)) + 
  geom_point(alpha=0.10) + facet_wrap(~species, ncol=3) + 
  theme_bw()

ggsave(filename = "figs/15_species_mean_locs_lon.png", height = 10, width=8)

#LATITUDE
ggplot(weighted_mean_locs, aes(day, weighted_lat)) + 
  geom_point(alpha=0.10) + 
  facet_wrap(~species, ncol=3) + 
  theme_bw()

ggsave(filename = "figs/15_species_mean_locs_lat.png", height = 10, width=8)

```

After this code is completed, run *migration-paths.Rmd* for the next step of the analysis.
