---
title: "Migration-path.Rmd"
author: "Sarah Supp"
date: "2/10/2020"
output: html_document
---

##Code for cedar waxwing project, modified from eBird migration project (Supp et al. 2015)
(c) 2022, Niu and Supp and Lee
supps@denison.edu
Denison University
Code is under development, part of NSF Multi-Institution Collaborative Award (2019-2)
modified from previous code developed for Supp et al. 2015 hummingbird paper (Ecography)

Birds evaluated include: 
* Cedar Waxwing (CEWA) _Bombycilla cedrorum_
* Robin (ROBI) _Turdus migratorius_
* Wood Thrush (WOTH) _Hylocichla mustelina_
* Yellow-rumped Warbler (YEWA) _setophaga coronata_
* Blue Jay (BLJA) _Cyanocitta cristata_
* European Starling (EUST) _Sturnus vulgaris_
* Eastern Bluebird (EABL) _Sialia sialis_
* Northern Mockingbird (NOMO) _Mimus polyglottos_
* Downy Woodpecker (DOWO) _Dryobates pubescens_
* Eastern Meadowlark (EAME) _Sturnella magna_
* White-breasted Nuthatch (WHNU) _Sitta carolinensis_
* Purple Finch (PUFI) _Haemorhous purpureus_
* Northern Cardinal (NOCA) _Cardinalis cardinalis_
* Dark-eyed Junco (DAJU) _Junco hyemalis_
* American Crow (AMCR) _Corvus brachyrhynchos_

```{r setup, include=FALSE} 
knitr::opts_chunk$set(echo = TRUE)

library(here)
library(data.table)
library(devtools)
#devtools::install_github("dkahle/ggmap")
library(ggplot2)
library(ggmap)
library(ggpubr)
library(lubridate)
library(sp)
library(maptools)
library(fields)
library(raster)
library(rgdal)
library(rgeos)
library(sf)
library(maps)
library(mapdata)
library(mgcv)
library(gamm4) 
library(ggpubr)
#devtools::install_github('r-barnes/dggridR', vignette=TRUE, force = TRUE)
library(dggridR)
library(RColorBrewer)
library(geosphere)
library(radiant.data)
library(rnaturalearth)
#devtools::install_github("ropensci/rnaturalearthhires")
library(rnaturalearthhires)
#install.packages('remotes')
#remotes::install_version('SDMTools','1.1-221')
library(SDMTools)#FIXME: package ‘SDMTools’ is not available (for R version 3.6.2)
#devtools::install_github("r-spatial/sf") #C compiler error on mac
library(geojsonio)
library(dplyr)
library(tidyverse)
library(nvctr)
library(gapminder)
```

If starting from scratch, input the three raw data files and merge together.
You need to bring in: 
1. a file with the bird observations (ebrd2.c)
2. a file with the total eBirder "effort" (eft.c)
3. a file with all the center locations for the POLYFID grid cells (locs)

*Please go to the file* called "process-raw-eBird-data.Rmd" to do this, if you don't already have the files named with the pattern dat_effort_****.RData".

**If you have already completed the initial steps** and have saved out the effort file, start here instead, with loading it.
Each species has it's own merged data file, and will be brought into one species data (spdata) file to work through the results.
```{r}
# files = list.files(path=here(), recursive=T, pattern=glob2rx("dat_effort*.rds"))
files = list.files(path=here("data/effort-merged_data/"), pattern=glob2rx("dat_effort*.rds"))

spdata <- data.frame(POLYFID=0, year=0, day=0, count=0, x=0, y=0, effort=0, species="none")
for (i in files) {
  dat <- readRDS(paste0(here("data/effort-merged_data/"),(i)))
  spdata <- bind_rows(spdata, dat)
}
spdata <- spdata %>% filter(year!="0")
```

[La Sorte et al. 2014](https://onlinelibrary.wiley.com/doi/full/10.1111/jbi.12328) defined western, central, and eastern flyways for migrating songbirds. These are general, but since our species include populations across the continent, and we are focused on eastern and midwestern populations of eastern redcedar, we should exclude western occurrences (<103 longitude).
```{r}
#TODO/FIXME: After running "process-raw-eBrid-data" and re-run the *spdata*, the names of the variables (columns names) are changed. For example, in num_spobs function, count.x is not found in dat_effort. YEAR and DAYS have to be change into lower case letter. 

#FIXME: Do we need num_spobs? 

#dat_effort is giving me an error because there is no column name lon
#dat_effort <- spdata %>%
  #dplyr::filter(lon >=-103)

# x = longitude 
dat_effort <- spdata %>%
  dplyr::filter(x >= -103)

num_obs <- nrow(dat_effort)

paste0("The total number of observations for all species is ", num_obs, ".")


num_spobs <- dat_effort %>%
  filter(year!=2020) %>%
  group_by(species) %>%
  summarise(nrow=n(),
            total=sum(count))

num_spobs

dat_effort %>%
  filter(year!=2020) %>%
  group_by(species, year) %>%
  summarise(nrow=n(),
            total=sum(count)) %>%
  ggplot(aes(as.numeric(year), total, group=species)) + 
  geom_point(aes(shape=species)) + 
  geom_line() + 
  scale_y_log10() + 
  scale_x_continuous(breaks=seq(2008, 2020, 3)) +
  #  scale_x_discrete(limits=c("2008", "2012", "2016", "2019")) +
  xlab("Year") +
  ylab("checklist count") +
  theme(legend.position=("none")) +
  facet_wrap(~species, ncol=1) + 
    # set transparency
    theme(
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = "transparent",colour = NA),
        plot.background = element_rect(fill = "transparent",colour = NA)
        ) 

# Figure for ESA 2021 poster

#FIXME: ggasve is not working (error message:Error in grDevices::dev.off() : QuartzBitmap_Output - unable to open file 'figs/checklist_counts.png')

ggsave("figs/checklist_counts.png", bg="transparent", height=8, width=3)
```


---->## Weight mean locations 
Weight species counts by eBirder effort counts for each cell
```{r} 
#ordering issues 

copy <- data.frame(dat_effort)

copy <- copy[c(order(copy$year, copy$day)),]
  
df <- data.frame(copy)

#df <-df[c(1:50000),]

df$freq <- df$count/df$effort

#creating a columns for newx, newy, newz with NA values to store values of 3 vectors
df$newx <- NA
df$newy <- NA
df$newz <- NA


#takes about 20 hours to run it
#For each species of a given year and day, converting x and y to newx, newy, newz(radius)
for (i in 1:nrow(df)){
  df[i,"newx"] <- lat_lon2n_E(rad(df[i, "y"]),rad(df[i,"x"]))[1]
  df[i,"newy"] <- lat_lon2n_E(rad(df[i, "y"]),rad(df[i,"x"]))[2]
  df[i,"newz"] <- lat_lon2n_E(rad(df[i, "y"]),rad(df[i,"x"]))[3]
}

#saving converted nvector data frame 
save(df, file = "df_nvector")

# Save a single object to a file
saveRDS(df, "df_nvector.rds")

# Restore it under a different name
#df <- readRDS("df_nvector.rds")

#Dr. Lavin`s code 
# df_w_weights <- df %>% mutate(weightedx=newx * freq, weightedy=newy * freq, weightedz=newz * freq)
# df_summary <- df_w_weights %>% group_by(year, day, species) %>% summarise(weighted_lat=mean(weightedy), weighted_lng=mean(weightedx), numobs=sum(count), numcells=n())


#putting species, year, and days into list in order to see the unique varaibles of each
species_list <- unique(df$species)
year_list <- unique(df$year)
day_list <- unique(df$day)

#For each species of a given year and day, converting newx, newy, newz back into decimal meanx and meany
weighted_mean_locs <- NULL
for (i in 1:length(species_list)){
  
  species_df <- df[df$species==species_list[i],]
  
  for (j in 1:length(year_list)){
  
    year_df <- species_df[species_df$year==year_list[j],]
  
    for(k in 1:length(unique(year_df$day))){
    
        day_list <- sort(unique(year_df$day))
  
        day_df <- year_df[year_df$day==day_list[k],]

        mean_cal <- c(weighted.mean(day_df$newx, day_df$freq),
                      weighted.mean(day_df$newy, day_df$freq),
                      weighted.mean(day_df$newz, day_df$freq))


        mean_cal <- deg(n_E2lat_lon(mean_cal)) #degree func
        
        weighted_mean_locs <- rbind(weighted_mean_locs, data.frame(day=day_list[k], 
                                     weighted_lon=mean_cal[2], 
                                     weighted_lat=mean_cal[1],
                                     year=year_list[j],
                                     species=species_list[i]))
    }
  }
}  



sample <- df %>% group_by(species, year, day) %>% summarise(numcells = n(), numobs = sum(count))

weighted_mean_locs <- cbind(weighted_mean_locs, sample[c("numcells", "numobs")])

weighted_mean_locs <- weighted_mean_locs[,c(5,4,1,2,3,6,7)]
  
#plot the weighted standard deviations by species, just to check
ggplot(weighted_mean_locs, aes(weighted_lon)) + geom_histogram() + facet_wrap(~species)
ggplot(weighted_mean_locs, aes(weighted_lat)) + geom_histogram() + facet_wrap(~species)

#check if weighted sd differs by time of the year (expect to be higher during migration, lower during breeding)
ggplot(weighted_mean_locs, aes(day, weighted_lon)) + geom_point(alpha=0.10) + facet_wrap(~species)
ggplot(weighted_mean_locs, aes(day, weighted_lat)) + geom_point(alpha=0.10) + facet_wrap(~species)




#Dr.supp old code
# weighted_mean_locs <- dat_effort %>%
#     mutate(day = as.numeric(day),
#          year = as.numeric(year)) %>%
# group_by(species, year, day) %>%
#   summarise(
#             numcells = n(), 
#             numobs = sum(count.x),
#             wtmean_lon = weighted.mean(lon, count.x/count.y), 
#             wtmean_lat = weighted.mean(lat, count.x/count.y), 
#             wtsd_lon = weighted.sd(lon, count.x/count.y),
#             wtsd_lat = weighted.sd(lat, count.x/count.y) 
#             ) %>%
#   ungroup()


# #plot the weighted standard deviations by species, just to check
# ggplot(weighted_mean_locs, aes(wtsd_lon)) + geom_histogram() + facet_wrap(~species)
# ggplot(weighted_mean_locs, aes(wtsd_lat)) + geom_histogram() + facet_wrap(~species)
# 
# #check if weighted sd differs by time of the year (expect to be higher during migration, lower during breeding)
# ggplot(weighted_mean_locs, aes(DAY, wtsd_lon)) + geom_point(alpha=0.10) + facet_wrap(~species)
# ggplot(weighted_mean_locs, aes(DAY, wtsd_lat)) + geom_point(alpha=0.10) + facet_wrap(~species)
```

Cardinalis_cardinalis, Corvus_brachyrhynchos, Cyanocitta_crista, Drybates_pubescens, Mimus_polyglottos, Sialia_sialis, Sitta_carolinensis, Sitta_carolinensis, Stumus_vulgaris, are non-migratory bird species. 

## Add more detail to dates in the weighted mean location dataframe
A DATE and MONTH formatted column to mean_daily_locs dataframe. TODO
An ID column is also added, which is an integer of each of the dates in order, 1-4383.
**It is important to note when converting to Dates that for this data type only (why!?!) R uses a 0 based index. This means Day 1 is 0. So to convert our "day of year" integers to a Year-Month-Day format, we need to use DAY-1 and YEAR.**
```{r}
weighted_mean_locs <- weighted_mean_locs %>%
  mutate(DAYm1 = day-1,
         origin = paste0(year, "-01-01"),
         date = as.Date(DAYm1, origin=origin), 
         month = month(date)) %>%
  mutate(winter = ifelse(month %in% c(10, 11, 12, 1, 2, 3), "winter", "non-winter")) %>%
  arrange(species,date) %>%
  ungroup() %>%
  mutate(ID = row_number()) %>%
  dplyr::select(-DAYm1, -origin)
```


Count number of records by year *for 2020 NSF report*
```{r}
#count total number of records across the years. (increasing strongly)
counts <- df %>%
  group_by(species, year) %>%
  tally()

num_bins <- ggplot(counts, aes(year, n)) + geom_bar(stat="identity") + 
  theme_bw() + ylab("Number of binned observations") + xlab("Year") +
  theme(axis.text.x = element_text(angle = 90)) + 
  facet_wrap(~species, ncol=1)

#checking how many unique grid cells logged an observation in each year (relatively flat)
nPOLYFID <- df %>%
  group_by(species, year) %>%
  summarise(n=n_distinct(POLYFID))

num_gridcells <- ggplot(nPOLYFID, aes(year, n)) + geom_bar(stat="identity") + 
  theme_bw() + ylab("Number of unique grid cells") + xlab("Year") +
  theme(axis.text.x = element_text(angle = 90)) + 
  facet_wrap(~species, ncol=1)

#checking how many days per year have at least 1 observation (ALL of them)
nDAYSofyear <- df %>%
  group_by(species, year) %>%
  summarise(n=n_distinct(day))

num_days <- ggplot(nDAYSofyear, aes(year, n)) + geom_bar(stat="identity") + 
  theme_bw() + ylab("Number of unique days per year") + xlab("Year") +
  theme(axis.text.x = element_text(angle = 90)) + 
  facet_wrap(~species, ncol=1)

ggarrange(num_bins, num_gridcells, num_days,
          labels=c("A", "B", "C"),
          ncol=3, nrow=1)

#ggsave(filename = "figs/species_obs.png", height = 11, width=8)
```


Initial plot of bird average locations for all species and latitude by day across years *for 2020 NSF report*
```{r}
# ggplot(weighted_mean_locs, aes(wtmean_lon, wtmean_lat)) +
#   geom_point(alpha=0.25) + geom_line(alpha=0.25) +
#   facet_wrap(~YEAR)

ggplot(weighted_mean_locs, aes(day, weighted_lon, group=year)) +
  geom_point(alpha=0.25, aes(col=winter)) + geom_line(alpha=0.25) +
  facet_wrap(~year)

ggplot(weighted_mean_locs, aes(as.numeric(day), weighted_lat, group=year)) +
  stat_smooth(aes(col=as.numeric(year))) + ylab("Weighted mean latitude") +
  xlab("Day of the year") + 
  scale_x_continuous(breaks = seq(1, 366, by = 60)) +
  facet_wrap(~species)
```


## Calculates the count of observations within each cell, 
weighted by total eBirder effort on that day in a given cell. 
Appends into the dataframe as "count_weighted" for analysis. Weighted as the total number of observations of the target species in a cell divided by the total number of eBirder records in a cell.
```{r}
#using original data(dat_effort=df)
dgg <- dgconstruct(project = "FULLER", aperture = 4, topology = "HEXAGON", res = 6)
df$cell <- dgGEO_to_SEQNUM(dgg, df$x, df$y)$seqnum
df$cell_lat <- dgSEQNUM_to_GEO(dgg, df$cell)$lat_deg 
df$cell_lon <- dgSEQNUM_to_GEO(dgg, df$cell)$lon_deg 

#cellcenters   <- dgSEQNUM_to_GEO(dgg, dat_effort$cell)
spp_counts <- df %>%
  group_by(species, cell) %>% 
  summarise(sum_weighted_count=sum(freq),
            mean_weighted_count=mean(freq),
            sum_count=sum(count))
# 
# ggplot(spp_counts, aes(x=sum_weighted_count)) +
#   geom_histogram(binwidth=10)

ggplot(spp_counts, aes(x=mean_weighted_count)) +
  geom_histogram(binwidth=0.01) + 
  facet_wrap(~species)
# 
# ggplot(spp_counts, aes(x=sum_count)) +
#   geom_histogram(binwidth=100)
```


## Create a map of eBird effort (all years, all dates)
across eastern North America

FIXME: dgcellstogrid not working (frame=TRUE, wrapcells=TRUE). Without (frame=TRUE, wrapcells=TRUE), grid does not has cell column 
```{r}
#Get the grid cell boundaries for cells which had bird observations
#FIXME: dgcellstogrid and merging is not working 

#grid <-  dggridR::dgcellstogrid(dgg, spp_counts$cell, frame=TRUE, wrapcells=TRUE) #->not working 
grid <- dgcellstogrid(dgg, spp_counts$cell) #-> working.. IS this correct?s

#changing dgg into dataframe 
#dgg2<-as.data.frame(dgg)
#grid2 <-  dggridR::dgcellstogrid(dgg2, spp_counts$cell) #->not working 
#grid3 <- merge(grid2, spp_counts) -> gives 3801168 obs. of 7 variables
#grid33 <- base::merge(grid2, spp_counts, by = c("cell")) -> give 1008 obs. of 2 variables 

#Update the grid cells' properties to include the number of observations in each cell
grid <- merge(grid, spp_counts, by="cell")
grid <- merge(grid, spp_counts, by.x="cell", by.y="cell")
#zoom to just eastern USA
grid <- grid %>%
  filter(long >= -103,
         lat >= 25)
#Get polygons for the spatial range and make a map of bird observations
countries <- map_data("usa") 

ggplot() + 
  #geom_polygon(data=countries, aes(x=long, y=lat, group=group), fill=NA, color="black")   +
  geom_polygon(data=grid, aes(x=long, y=lat, group=cell, fill=mean_weighted_count), alpha=0.4)    +
  geom_path   (data=grid, aes(x=long, y=lat, group=cell), alpha=0.4, color="white") +
#  geom_point  (aes(x=cellcenters$lon_deg, y=cellcenters$lat_deg), size=0.5) +
  scale_fill_gradient(low="gray90", high="black") + 
  #scale_fill_gradient2(low="blue", high="red", midpoint = 250) 
  theme_bw() + 
  facet_wrap(~species)
```


## Create a map of species counts (all years, all dates)
across eastern North America


FIXME: dgcellstogrid not working (frame=TRUE, wrapcells=TRUE). 
```{r}
#TODO: Make how you prefer, but feel free to plot the data as the actual locations of the birds 
#       (from the .csv files), or to use the .Rdata files to plot the polygon center, maybe with 
#       point sized or colored by magnitude of the count.

#FIXME:dgcellstogrid not working 

#all_states <- map_data("state")
state_prov <- rnaturalearth::ne_states(c("united states of america", "canada"))
#states <- subset(all_states, region %in% c('ohio', 'michigan', 'kentucky', 'tennessee', 'indiana', 
#                                           'illinois', 'iowa', 'nebraska','south dakota', 'north dakota',
#                                           'minnesota', 'wisconsin', 'missouri', 'kansas'))
uw_spp_counts <- df %>%
  group_by(species, cell) %>% 
  summarise(count_new_uw=sum(count))


uw_grid <- dgcellstogrid(dgg, uw_spp_counts$cell, frame=TRUE, wrapcells=TRUE)
uw_grid <- merge(grid, uw_spp_counts, by.x=c("cell", "species"), by.y=c("cell", "species")) 

p <- ggplot() +
  geom_polygon(data=state_prov, 
                aes(x=long, y=lat, group = group), colour="black", fill="white") +
  geom_polygon(data=uw_grid, 
               aes(x=long, y=lat, group=cell, fill=count_new_uw), alpha=0.4) +
  geom_path(data=uw_grid, 
            aes(x=long, y=lat, group=cell), alpha=0.4, color="white") +
  xlim(-102,-52) +
#  geom_point  (aes(x=cellcenters$lon_deg, y=cellcenters$lat_deg), size=0.5) +
  scale_fill_gradient(low="red", high="yellow") +
#  scale_fill_gradient2(low="blue", high="red",midpoint = 10000 ) +
  labs(title="Bird locations") + 
  theme_bw() + 
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) + 
  facet_wrap(~species)
p
```


## Estimate migration pathway for Bombycilla each year separately using GAMs
Use GAM model to predict daily location along a smoothing line, from the weighted mean locations. Daily location should be calculated for each year separately.

In the GAM, we can use the weighted mean locations (latitude and longitude) that we have already calculated above. These become the inputs to the gam model, which finds the predicted (smooth) migration path for each day. The predicted (fitted) values become the migration path for the species, which we will then use to estimate start of spring, peak latitude (breeding), and end of autumn migration. Between end Autumn migration and begin of Spring migration, is the expected time that most individual birds are on their wintering grounds and not actively migrating. 

*Creates a dataframe with daily location for each year and graphs results*
```{r}
Estimatedailylocs = function(dat) {

  x <- c(2008:2022)
  spp <- unique(dat$species)

  df_dailylocs <- data.frame(species = "none", day = 0, year =0, month = 0, winter = "not", lon = 0, lat = 0, lon_se = 0, lat_se = 0)

  for (s in spp){
    for (i in x) {
      sub_weighted_mean_locs <-
        dat %>%
        filter(year == i & species == s)

      lon_gam = gam(weighted_lon ~ s(day, k=20), data = sub_weighted_mean_locs, gamma = 1.5)
      lat_gam = gam(weighted_lat ~ s(day, k=20), data = sub_weighted_mean_locs, gamma = 1.5)
      xpred = data.frame(day=sort(unique(sub_weighted_mean_locs$day)))
      lonpred = predict(lon_gam, newdata = xpred, type="response", se.fit=T)
      latpred = predict(lat_gam, newdata = xpred, type="response", se.fit=T)

      preds =  data.frame(species = s, day = xpred$day, year = i,
                          month = sub_weighted_mean_locs$month, winter = sub_weighted_mean_locs$winter,
                          lon = lonpred$fit, lat = latpred$fit, lon_se = lonpred$se.fit, lat_se = latpred$se.fit)
      df_dailylocs <- data.frame(bind_rows(df_dailylocs, preds))
    }
  }
  df_dailylocs = df_dailylocs[-1,]
  return(df_dailylocs)
}

#get daily centroid locations for all species in all years
dailylocs <- Estimatedailylocs(weighted_mean_locs)

ggplot(dailylocs, aes(day, lat)) + geom_line(size=1, aes(col=species)) +
  # geom_vline(xintercept=c(101, 209, 362), col="gray30") + #FIXME: Update xintercepts with dates
  facet_wrap( ~ year, ncol=3)+ xlab("Day of Year") + ylab("weighted mean latitude") +
  theme_bw()

ggplot(dailylocs, aes(lon, lat, group=year)) +
  geom_point(aes(col=winter), alpha=0.25) +
  scale_colour_manual(values = c("grey50", "blue")) +
  facet_wrap(~species)

ggplot(dailylocs, aes(lon, lat, group=year)) +
  geom_point(aes(col=winter), alpha=0.25) +
  scale_colour_manual(values = c("grey50", "blue")) +
  facet_grid(year~species)

#FIXME: For relevance to ERC, we have some generic winter months, labeled in blue, but will need to also determine the lat-long of interest. For example, Hylocichla mustelina is definitely migrating during the winter, but much of this may be further south than the main area of interest, and not fully relevant during all of the winter time frame.
```


## Find the distances traveled between the mean locations. 
This calculation uses Great Circle (ellipsoid) distance on the estimated daily locations from the GAM model predictions for latitude and longitude. Because of the way the distVicentyEllipsoid function works on the values, the rows *must* all be in chronological order.
```{r}
#identify dates with no location and assign all values to NA
missdates <- dailylocs %>%
  group_by(species, YEAR) %>%
  #technically this leaves out DAY 366 in 2008, 2012, 2016, and 2020, but I don't think that matters?
  summarize(missing = setdiff(1:365, DAY)) %>% 
  mutate(DAY = missing, MONTH=NA, winter=NA, lon=NA, lat=NA, lon_se=NA, lat_se=NA) %>%
  dplyr::select(species, DAY, YEAR, MONTH, lon, lat, lon_se, lat_se)

#append the missing/NA date values to the main dailylocs dataframe
dailylocs <- bind_rows(dailylocs, missdates)

#calculate sequential distances using geosphere::distVicentyEllipsoid, adds NA for the first record
calc_distances <- function(lon, lat) {
  m <- cbind(lon,lat)
  dist <- append(NA, distVincentyEllipsoid(m))/1000
  return(dist)
}

dailylocs <- dailylocs %>%
  # ensures that everything is ordered chronologically by year and day of year
  arrange(species, YEAR, DAY) %>%
  group_by(species, YEAR) %>%
  #calculate sequential distances, adds NA for the first record
  mutate(distance = calc_distances(lon, lat)) %>%
  #Remove Day 1 for all year, because due to our method of separating GAM by year, it will be a flawed value
  filter(DAY != 1)


#TODO: If placed after the dates are calculated, then the speeds used can be limited to the migration seasons using the filter below. Not sure we need to do that here, but I think this is how I got around the year-to-year day 1 being wrong things last time, plus, that project was really only focused on the migration seasons alone.
#  filter(DAY >= migration_dates$spring_begin & migration_dates <= migration_dates$autumn_end)

#FIXME: 
ggplot(dailylocs, aes(as.numeric(DAY), distance, group=YEAR)) + geom_line(aes(col=species)) + 
  theme_bw() + xlab("Julian Day") + ylab("Distance Traveled (km)") + 
  theme(text = element_text(size=12)) + 
  facet_wrap(~species)#+  
  #geom_vline(xintercept = median(migr_dates), col = "indianred", linetype = "dashed")

ggsave(filename = "figs/species_distances.png", height = 5, width=8)
```

## Estimate the maximum migration speed during migration 
First, remove all values for Day = 1. Because each GAM was calculated separately by year, distance between Dec 31 and Jan 1 will not be valid. 
Use the median of the top 5 migration speeds for each year separately, as the estimated maximum migration speed (km/day) for the species. 
```{r}

# function to estimate the maximum speed of migration (km/day)
EstimateMaxSpeed = function(dat) {
  dat <- dat %>%
  filter(DAY != 1)
  years <- c(2008:2019)
  species <- unique(dat$species)
  df <- data.frame(species = "none", YEAR = 0, MAX_SPEED = 0)
  for (s in species){
    for (i in years){
   sub_dailylocs <- 
       dailylocs %>%
       filter(YEAR == i & species == s)
  
    median <- median(tail(sort(sub_dailylocs$distance),5))
  
    max_speed <-  data.frame(species = s, YEAR = i, MAX_SPEED = median)
  
    df <- data.frame(bind_rows(df, max_speed))
  
    }
  }
  df = df[-1,]
return(df)
}

#estimate the maximum migration speed for each year
max_speed <- EstimateMaxSpeed(dailylocs)

speeds <- max_speed %>%
  group_by(species) %>%
  summarise(
    mean = mean(MAX_SPEED),
    sd = sd(MAX_SPEED),
    median = median(MAX_SPEED)
  )

#plot the results estimating yearly maximum migration speed (km/day)
ggplot(max_speed %>% filter(species!="Cyanocitta cristata"), aes(YEAR, MAX_SPEED)) + geom_line(aes(col=species)) + 
  theme_bw() + xlab("Year") + ylab("Max Speed (km/day)") + 
  theme(text = element_text(size=12),
        legend.position="bottom") + 
  scale_x_continuous(breaks=seq(2008, 2019, 3))

#suggest using points instead of lines, because we're not really plotting something continuous with an expected trend here, where speed in one year depends on speed in the previous year (depends on weather/climate?)
ggplot(max_speed, aes(YEAR, MAX_SPEED)) + geom_point() +
  #geom_hline(yintercept = med, linetype="dashed", col="hotpink") +
  theme_bw() + xlab("Year") + ylab("Max Speed (km/day)") + 
  theme(text = element_text(size=20), 
        axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5),
        legend.position="bottom") + 
  scale_x_continuous(breaks=seq(2008, 2019, 3)) +
 # annotate(geom="text", x= 3, y= 50, label=paste0("median = ", round(med,2), " km/day")) + 
  facet_wrap(~species)

#ggsave(filename = "figs/WOTH_MedMaxMigrationSpeed.png")
```



# estimate 3 migration dates, beginning of spring, peak latitude (summer), end of fall migration
This will need some editing to work on each year separately. Ideally a resulting data frame with columns for year, begin_spring, peak_latitude, end_autumn

```{r}
# modified from old function Est3MigrationDates in migration-fxns.R

Est3MigrationDates = function(dat){
  #takes in predicted centroids for migration path, and estimates the beginning of spring migration,
  # the end of fall migration, and the date where the species reaches maximum latitude.
  dat <- dat %>%
  filter(DAY != 1)
  year <- c(2008:2019)
  species <- unique(dat$species)
  df <- data.frame(species="none", YEAR=0, SPRING = 0, MAXLAT = 0, FALL = 0)
  for (s in species) {
    for (y in year){
   dat_subset <- 
       dat %>%
       filter(YEAR == y & species == s) %>%
     filter(!is.na(lon))
   print(paste0("species: ", s, "; year: ", y))
    #GAM model on predicted latitude of centroids by julian date
    #gam1 = gam(wtmean_lat ~ s(DAY, k = 40), data = dat, gamma = 1.5) 
    #xpred = data.frame(DAY = c(1:max(dat$DAY)))
    #dpred = predict(gam1, newdata=xpred, type="response", se.fit=TRUE)
    
    ## cutoff based on 2 SE for spring and fall combined, following La Sorte et al. 2013 methods
    # Spring migration should be between 11 Jan and 9 July
    # Fall migration should be between 8 August and 21 Dec
    #NOTE: These dates are seeking Jan 1-May 31 for Spring migration begin
    #                 AND          Aug 1-Dec 30 for Fall migration end 
   # CHANGED FROM PREVIOUS CODE FOR HUMMINGBIRD PROJECT
   # ALSO ADDED NA.RM=TRUE ARGUMENT, DOES THIS HAVE ANY DOWNSIDES?
   spring_threshold = min(filter(dat_subset, DAY %in% c(1:151))$lat_se*2.56 + filter(dat_subset, DAY %in% c(1:151))$lat, na.rm=TRUE)
   fall_threshold = min(filter(dat_subset, DAY %in% c(213:364))$lat_se*2.56 + filter(dat_subset, DAY %in% c(213:364))$lat, na.rm=TRUE)
    #FIXME: after removing DAY=1, there are years with 364 days and with 365 days.If we ignore the last day of the leap years, will this influence fall threshold?
 spring_index = intersect(c(11:190), dat_subset$DAY) # between 11 Jan and 9 July #FIXME: what should these dates be, they don't match
    fall_index = intersect(c(220:355), dat_subset$DAY) # between 8 August and 21 Dec
    spring_max = (dat_subset %>% filter(DAY %in% spring_index) %>% slice_max(lat))$DAY
    fall_max =  (dat_subset %>% filter(DAY %in% fall_index) %>% slice_max(lat))$DAY
    
    #identify beginning of spring migration
    tst = 1000
    spring_index2 = spring_max
    while(tst > spring_threshold){
      if(nrow(filter(dat_subset, DAY==spring_index2))>0) {
        tst = filter(dat_subset, DAY %in% spring_index2)$lat
        if(spring_index2 == 1) break
        spring_index2 = spring_index2 - 1
      }
      else { spring_index2 = spring_index2 - 1 }
    }
    spring_begin = spring_index2 + 1
    
    #identify end of fall migration
    tst <- 1000
    fall_index2 = fall_max
    while(tst > fall_threshold){
     # print(paste0("tst= ", tst, " fall_index2= ", fall_index2))
      if(nrow(filter(dat_subset, DAY==fall_index2))>0) {
        tst = filter(dat_subset, DAY==fall_index2)$lat
        if(fall_index2 == 1) break
        fall_index2 = fall_index2 + 1
      }
      else { fall_index2 = fall_index2 + 1 }
    }
    fall_end <- fall_index2 - 1
    
    # find center of the season, maximum latitute (e.g. population is no longer moving further north; breeding)
    max_lat = dat_subset[dat_subset$lat == max(dat_subset$lat),]$DAY
    
    dates = data.frame(species = s, YEAR = y, SPRING = spring_begin, MAXLAT = max_lat, FALL = fall_end)
    
    df <- data.frame(bind_rows(df, dates))
    }
  }
  df = df[-1,]
return(df)
}

#blue jays don't really migrate? Should I remove them from this part of the analysis:
dailylocs_4spp <- dailylocs %>% filter(species != "Cyanocitta cristata")
dates <- Est3MigrationDates(dailylocs_4spp) 

median_migdates <- dates %>%
  group_by(species) %>%
  summarise(begin_winter = median(FALL),
            end_winter = median(SPRING))

# paste0("The beginning of winter is on average day ", begin_winter, " and the end of winter is on average day ", end_winter, ".")

begin <- ggplot(dates, aes(YEAR, FALL)) + 
  geom_point() + 
  geom_smooth(method="lm") +
  #geom_hline(yintercept = begin_winter, linetype="dashed", col="hotpink") +
  theme_bw() + xlab("Year") + ylab("Winter begin date") + 
  theme(text = element_text(size=14), axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) + 
  scale_x_continuous(breaks=seq(2008, 2019, 3)) +
 # annotate(geom="text", x= 2012, y= 340, label=paste0("median doy = ", round(begin_winter,2)))
  facet_wrap(~species)

end <- ggplot(dates, aes(YEAR, SPRING)) + 
  geom_point() + 
  geom_smooth(method="lm") +
 # geom_hline(yintercept = end_winter, linetype="dashed", col="hotpink") +
  theme_bw() + xlab("Year") + ylab("Winter end date") + 
  theme(text = element_text(size=14), axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +  
  scale_x_continuous(breaks=seq(2008, 2019, 3)) +
  #annotate(geom="text", x= 2012, y= 55, label=paste0("median doy = ", round(end_winter,2)))
  facet_wrap(~species)

ggarrange(begin, end,
          labels=c("A", "B"),
          ncol=2, nrow=1)

ggsave(filename = "figs/allspp_winterDates.png", height = 5, width=8)
```

Let's look at the linear trends of these dates for species, especially S. coronata.
```{r}
scoronata_spring <- dates %>%
  filter(species=="Setophaga coronata")

mod1 <- lm(SPRING ~ YEAR, data=scoronata_spring)
summary(mod1)
```


Now we might just want to look at bird occurrences during the winter months, and in the latitudes that ERC occur in: 
Can use the winter column to grab all data October-March and the latitudes ~ 26-47 --Note that these choices are somewhat arbitrary, just to get a quick look now. Will need to get finer grained info from D. Ward and lab later...
```{r}
ERCbirds <- dailylocs %>%
  filter(lat - lat_se > 27 & lat + lat_se < 47 & winter=="winter")

ggplot() + 
  geom_polygon(data=state_prov, aes(x=long, y=lat, group = group), colour="grey50", fill="white") + 
  geom_point(data=ERCbirds, aes(lon, lat, col=species), size=.1) + 
  xlim(-102,-52) + 
  theme_bw() + 
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) + 
  facet_wrap(~MONTH)

```

# look at the dat_effort file locations, not just the daily locs (which are summarized centroids only)
```{r}
winter_dat_effort <- dat_effort %>%
  mutate(DAYm1 = DAY-1,
         origin = paste0(YEAR, "-01-01"),
         DATE = as.Date(DAYm1, origin=origin), 
         MONTH = month(DATE)) %>%
  mutate(winter = ifelse(MONTH %in% c(10, 11, 12, 1, 2, 3), "winter", "non-winter")) %>%
  arrange(species,DATE) %>%
  ungroup() %>%
  mutate(ID = row_number()) %>%
  dplyr::select(-DAYm1, -origin) %>%
  filter(winter=="winter") %>%
  filter(lat > 27 & lat < 47)


  ggplot() + 
  geom_polygon(data=state_prov, aes(x=long, y=lat, group = group), colour="grey50", fill="white") + 
  geom_point(data=winter_dat_effort, aes(lon, lat, col=species), alpha=.2, size=.1) + 
  xlim(-102,-52) + 
  theme_bw() + 
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) + 
  facet_grid(species~MONTH)

```


#--------------------------------------------------
#Start spatial analysis... 

Now, try to summarize the number of unique species in each POLYFID on each day in each year for the winter ERC season (can be counted as nrow())
```{r}
sppR <- winter_dat_effort %>%
  group_by(cell, cell_lat, cell_lon, YEAR, MONTH, DAY) %>%
  summarize(num_spp = n())

# sppR <- dat_effort %>%
#     mutate(DAYm1 = DAY-1,
#          origin = paste0(YEAR, "-01-01"),
#          DATE = as.Date(DAYm1, origin=origin), 
#          MONTH = month(DATE)) %>%
#   group_by(POLYFID, YEAR, MONTH, DAY) %>%
#   summarize(num_spp = n())

ggplot(sppR, aes(as.factor(num_spp), cell_lat)) + geom_boxplot() + 
  facet_wrap(~YEAR)
ggplot(sppR, aes(as.factor(num_spp), cell_lon)) + geom_boxplot() + 
  facet_wrap(~YEAR)

avg<- sppR %>%
  group_by(YEAR, MONTH) %>%
  summarize(mean = mean(num_spp), 
            median = median(num_spp))

avg2 <- sppR %>%
  group_by(YEAR, MONTH, DAY) %>%
  summarize(mean = mean(num_spp),
            median = median(num_spp))

ggplot(sppR, aes(DAY, num_spp)) + 
  geom_boxplot() + 
  facet_wrap(~MONTH)

ggplot(avg, aes(YEAR, mean)) + geom_point() + facet_wrap(~MONTH)
mod2 <- lm(mean~as.numeric(YEAR), data=avg)
summary(mod2)

ggplot(avg, aes(mean)) + geom_histogram(aes(fill=YEAR)) + facet_wrap(~MONTH)

ggplot(avg, aes(YEAR, median)) + geom_point() + facet_wrap(~MONTH)

ggplot(avg2, aes(DAY, mean)) + geom_point() + facet_grid(YEAR~MONTH, scale="free")


```

Calculate the number of species in a hex cell for each month (as opposed to day). Save as a table and then plot it on the grid cell map, using viridis color scale.
```{r}
sppR_mo <- sppR %>%
  group_by(cell, cell_lat, cell_lon, YEAR, MONTH) %>%
  summarise(Smed=median(num_spp), 
            Smax=max(num_spp),
            Smin=min(num_spp))

#Get the grid cell boundaries for cells which had bird observations
grid <- dgcellstogrid(dgg, sppR_mo$cell, frame=TRUE, wrapcells=TRUE)


#Update the grid cells' properties to include the number of observations in each cell
grid <- merge(grid, sppR_mo, by.x="cell", by.y="cell")

#zoom to just eastern USA
grid <- grid %>%
  filter(long >= -103,
         lat >= 25)
#Get polygons for the spatial range and make a map of bird observations
countries <- map_data("usa") 

grid2019 <- grid %>% filter(YEAR ==2010)

#plot just 2019, median values for the month
ggplot() + 
  #geom_polygon(data=countries, aes(x=long, y=lat, group=group), fill=NA, color="black")   +
  geom_polygon(data=grid2019, aes(x=long, y=lat, group=cell, fill=Smed), alpha=1)    +
  geom_path   (data=grid2019, aes(x=long, y=lat, group=cell), alpha=0.4, color="white") +
#  geom_point  (aes(x=cellcenters$lon_deg, y=cellcenters$lat_deg), size=0.5) +
  #scale_fill_gradient(low="gray90", high="black") + 
  scale_fill_viridis() +
  #scale_fill_gradient2(low="blue", high="red", midpoint = 250) 
  theme_void() + 
  facet_wrap(~MONTH)

ggsave("figs/winter2019.png", bg="transparent", height=7, width=11)

```

Calculate the slopes of species richness change across years, within cells. Plot the results to see if there is a trend of higher species disperser load through time. Need to think and check with FAL for ideas to see if we need to account for overall effort better (currently using as pres-only data, without weighted checks)
```{r}
# look at the structure of sppR_mo

cells <- unique(sppR_mo$cell)
months <- c(10, 11, 12, 1, 2, 3)
df <- data.frame(cell=0, month=0, n=0, slope=0, pVal=0, cell_lat=0, cell_lon=0)

for (c in cells){
  dat <- sppR_mo %>% filter(cell == c)
  for (m in months){
    dat2 <- dat %>% filter(MONTH == m)
    if (nrow(dat2) >= 3) {
      mod <- lm(Smed~as.numeric(YEAR), data=dat2)
      n = nrow(dat2)
      slope = coef(mod)[[2]]
      pVal = glance(mod)$p.value[[1]]
      cell_lat = dat2$cell_lat[1]
      cell_lon = dat2$cell_lon[1]
      
      df <- rbind(df, c(c, m, n, slope, pVal, cell_lat, cell_lon))
    }
  }
}
#remove the zero placeholder row and the NA values
#FIXME: are we dropping all the rows that has NA values? does sig = pValue? 
df <- df %>% 
  filter(n!=0) %>%
  #filter(!is.na(sig))
  #drop_na(df)
  
# adding factor names and levels to month, ordered by winter season, not calendar year
df$monthname <- month(as.numeric(df$month), label=TRUE)
df$monthname <- factor(df$monthname, levels=c("Oct", "Nov", "Dec", "Jan", "Feb", "Mar"))

# add column for significance
df$sig <- ifelse(df$pVal < 0.05, "sig", "NS")
  
#ggplot histogram, layered by identity for sig and NS
ggplot(df, aes(slope)) + 
  geom_histogram(aes(fill=sig), position="identity", alpha=0.5) +
  scale_fill_manual(values = c("gray", "darkturquoise")) + 
  geom_vline(xintercept=0, linetype="dashed", col="gray50") +
  theme_bw()

# ggplot boxplot by month for all significant slopes, commented code shows month comparisons, not currently included in figure
ggplot(df %>% filter(sig=="sig"), aes(monthname, slope)) + 
  geom_boxplot(fill="black", col="black", notch=TRUE) +
  geom_jitter(col="cyan3", alpha=0.5) +
  geom_hline(yintercept=0, linetype="dashed", col="black") +
  xlab("") +
  ylab("slope") +
#  stat_compare_means(method="wilcox.test", comparisons = list(c("Oct", "Nov"), c("Oct", "Jan"), c("Oct", "Feb"))) +
#  stat_compare_means(label = "p.signif", method = "t.test", ref.group = 1, hide.ns=TRUE) +
    theme(
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = "transparent",colour = NA),
        plot.background = element_rect(fill = "transparent",colour = NA),
        axis.text.y = element_text(colour="black", size=14),
        axis.title.y = element_text(colour="black", size=14)
        ) 
  #add significance, only difs were oct-nov, oct-jan, oct-feb
  # add text labels for mean slopes?

# Figure for ESA 2021 poster
ggsave("figs/Smed_slopes_month.png", bg="transparent", height=3, width=11)

#average effect size, mean of the slopes
df %>% 
  filter(sig=="sig") %>%
#  group_by(monthname) %>%
  summarize(meanslope = mean(slope),
            medianslope = median(slope))

#plot by latitude? any signal here?
ggplot(df %>% filter(sig=="sig"), aes(cell_lat, slope)) + 
  geom_point(alpha=0.10) + 
  geom_hline(yintercept=0, linetype="dashed") +
  geom_smooth(method="lm") + 
  facet_wrap(~monthname)

# Figure for ESA 2021 poster
ggsave("figs/sig_slopes_month_lat.png", bg="transparent", height=4, width=6)

# ggplot boxplot by month for all slopes, shaded jitter points by sig
ggplot(df, aes(monthname, slope)) + 
  geom_boxplot(fill="black", col="black", notch=TRUE) +
  geom_jitter(aes(col=sig), alpha=0.5) +
  scale_colour_manual(values=c("gray", "cyan3")) +
  geom_hline(yintercept=0, linetype="dashed", col="black") +
  xlab("") +
  ylab("slope") +
    theme(
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = "transparent",colour = NA),
        plot.background = element_rect(fill = "transparent",colour = NA),
        axis.text.y = element_text(colour="black", size=14),
        axis.title.y = element_text(colour="black", size=14)
        ) 

#some basic t.tests to show that all slopes (sig and sig+NS) were significantly different from Zero, and significantly positive (very few with lower richness through time) -- correlate to higher potential disperser load over the past decade -- could imply an increasing role for dispersers, but need to discuss with Frank what else we'd need to check to ensure that this isn't just due to increasing eBird effort (In retrospect I may not have yet controlled well for this, or need to use the weighted measures instead of presence only directly?)

```

Let's plot the map using the significant slopes, and all others shaded in grey
```{r}
#Get the grid cell boundaries for cells which had bird observations
grid <- dgcellstogrid(dgg, df$cell, frame=TRUE, wrapcells=TRUE)

#Update the grid cells' properties to include the number of observations in each cell
grid <- merge(grid, df, by.x="cell", by.y="cell")
#zoom to just eastern USA
grid <- grid %>%
  filter(long >= -103,
         lat >= 25)
#Get polygons for the spatial range and make a map of bird observations
countries <- map_data("usa") 

gridsig <- grid %>% filter(sig == "sig")
gridNS <- grid %>% filter(sig == "NS")

#plot significant values by viridis shades, nonsignificant values as grey
ggplot() + 
 # geom_polygon(data=countries, aes(x=long, y=lat, group=group), fill=NA, color="black")   +
  geom_polygon(data=gridsig, aes(x=long, y=lat, group=cell, fill=slope))    +
  geom_path   (data=gridsig, aes(x=long, y=lat, group=cell), alpha=0.4, color="white") +
#  geom_point  (aes(x=cellcenters$lon_deg, y=cellcenters$lat_deg), size=0.5) +
  #scale_fill_gradient(low="gray90", high="black") + 
  # scale_fill_viridis() +
  scale_fill_gradient2(low="navyblue", high="firebrick3", midpoint = 0) +
  geom_polygon(data=gridNS, aes(x=long, y=lat, group=cell), fill="grey") +
  #geom_path   (data=gridNS, aes(x=long, y=lat, group=cell), alpha=0.4, color="white") +
  theme_void() + 
  facet_wrap(~monthname, nrow=1) + 
  theme(legend.position = "left")

ggsave("figs/slope_Smed_change.png", bg="transparent", height=3.5, width=16)
```




#Little's range and FIA importance value species distribution map for Eastern red cedar
Try something with a shapefile
Downloaded this one for eastern red cedar from https://www.fs.fed.us/nrs/atlas/littlefia/species_table.html  
```{r}
#found some useful help here: https://www.earthdatascience.org/courses/earth-analytics/spatial-data-r/intro-to-coordinate-reference-systems/ 
#may also be useful to read thorugh here: https://geocompr.robinlovelace.net/reproj-geo-data.html 

# read shapefile
ERC <- readOGR(dsn = paste0(here(), "/data/shapefile/litt68av.shp"))
# convert to dataframe
ERC_df <- fortify(ERC)

# plot map using ggplot
ERCmap <- ggplot(ERC_df, aes(long,lat, group = group)) +
  geom_polygon(fill="darkolivegreen") +
  coord_equal() +
  labs(x = "Longitude (Degrees)",
       y = "Latitude (Degrees)",
      title = "ERC Range Map",
      subtitle = "D_Clarke_1866 Datum, Projection: Albers, Units: Degrees - Lat / Lon") + 
  theme_void()
ERCmap

# Figure for ESA 2021 poster
ggsave("ERC_range.png", ERCmap, bg="transparent")

#TODO reprojection of the range data is needed, or transformation of all other data including points to Albers, or it won't work.
# reproject data from Albers to WGS84 CRS
ERC_WGS84 = sf::st_transform(ERC, crs = "+proj=wgs84") #FIXME
ERC_WGS84 <- sp::spTransform(ERC,
                                CRS("+proj=wgs84")) #FIXME

# grab winter locations from the winter_dat_effort dataframe
# add a point to the map
mapLocations <- ERCmap +
                geom_point(data = winter_dat_effort,
                aes(x = lon, y = lat, group = NULL), colour = "orange",
                      size = .5)
mapLocations



--------------------------------
#FIXME: Error in ogrInfo(dsn = dsn, layer = layer, encoding = encoding, use_iconv = use_iconv,  : Cannot open data source
my_spdf <- readOGR( 
  dsn=paste0(here(), "/data/shapefile2/") , 
  layer="litt68av",
  verbose=FALSE
)

#explore the shapefile
summary(my_spdf)
length(my_spdf)
head(my_spdf@data)

# Basic plot of this shape file using Base R:
par(mar=c(0,0,0,0))
plot(my_spdf2, col="darkolivegreen", bg="grey80", lwd=0.25, border=0 )

# 'fortify' the data to get a dataframe format required by ggplot2
require(broom)
spdf_formytified <- tidy(my_spdf, region = "LITT68_ID")

# reproject data
spdf_WGS84 <- rgdal::spTransform(my_spdf,
                                crs(state_prov))

# get background map layers
state_prov <- rnaturalearth::ne_states(c("united states of america", "canada"))
us  <- map_data("usa")

# Plot it using ggplot2, just a shape, no context. Seems to be missing projection ?? Can't add points or background map.
ggplot() + 
  geom_polygon(data = spdf_fortified, aes( x = long, y = lat, group = group), fill="#69b3a2", color="white", alpha=0.25) +
  theme_void()

#TODO: Can't plot the shapefile onto the map because it isn't the right projection
#       sf should be abel to help this, maybe here? https://r-spatial.org/r/2018/10/25/ggplot2-sf-2.html 
ggplot(data = world) +
  geom_sf() + 
  geom_point(data=dat_effort, aes(x=lon, y=lat), size=0.2) + 
  coord_sf(xlim = c(-103, -48), ylim = c(24.5, 60), expand = FALSE) +
 #geom_polygon(data = spdf_fortified, aes( x = long, y = lat, group = group), fill="#69b3a2", color="white", alpha=0.25) +
  theme_void()
  
```


